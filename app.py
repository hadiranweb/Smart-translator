import streamlit as st
import fitz  # PyMuPDF
from huggingface_hub import InferenceClient
import openai
import time
import os
from dotenv import load_dotenv
from fpdf import FPDF
import tempfile

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ---
load_dotenv()
st.set_page_config(page_title="Ù…ØªØ±Ø¬Ù… Ù‡ÙˆØ´Ù…Ù†Ø¯", layout="wide")
st.title("ğŸ“– Ù…ØªØ±Ø¬Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ùˆ Ø²ÛŒØ±Ù†ÙˆÛŒØ³")

# Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ú©Ø±Ø¯Ù† Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ
st.markdown("""
<style>
p, div, h1, h2, h3, h4, h5, h6 {
    direction: rtl;
    text-align: right;
    font-family: 'Segoe UI', Tahoma, sans-serif;
}
</style>
""", unsafe_allow_html=True)

# --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ---
def create_pdf(text, filename="ØªØ±Ø¬Ù…Ù‡.pdf"):
    pdf = FPDF()
    pdf.add_page()
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙÙˆÙ†Øª Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ ÙØ§Ø±Ø³ÛŒ (Ù†ÛŒØ§Ø² Ø¨Ù‡ ÙÙˆÙ†Øª Ø¯Ø± Ù¾ÙˆØ´Ù‡ fonts)
    try:
        pdf.add_font("Persian", "", "fonts/arial.ttf", uni=True)
    except:
        st.warning("ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯! Ø§Ø² ÙÙˆÙ†Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        pdf.add_font("Arial", "", uni=True)
        pdf.set_font("Arial", size=12)
    else:
        pdf.set_font("Persian", size=12)
    
    pdf.multi_cell(0, 10, txt=text, align="R")
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù…ÙˆÙ‚Øª ÙØ§ÛŒÙ„ PDF
    temp_dir = tempfile.mkdtemp()
    pdf_path = os.path.join(temp_dir, filename)
    pdf.output(pdf_path)
    return pdf_path

def extract_text_from_file(uploaded_file, file_type):
    try:
        uploaded_file.seek(0)  # Ù…Ù‡Ù…: reset file pointer
        if file_type == "PDF":
            try:
                doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
                return "\n".join([page.get_text() for page in doc])
            except Exception as e:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† PDF: {str(e)}")
                return ""
        
        elif file_type == "Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT)":
            content = uploaded_file.read().decode("utf-8")
            return "\n".join([block.split('\n')[2] for block in content.split('\n\n') if len(block.split('\n')) >= 3])
        
        else:  # Ù…ØªÙ† Ø³Ø§Ø¯Ù‡
            return uploaded_file.read().decode("utf-8")
    
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„: {str(e)}")
        return ""

# --- Ù†ÙˆØ§Ø± Ú©Ù†Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ---
with st.sidebar:
    st.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡")
    file_type = st.radio(
        "Ù†ÙˆØ¹ ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ:",
        ["PDF", "Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT)", "Ù…ØªÙ† Ø³Ø§Ø¯Ù‡"]
    )
    
    model_choice = st.radio(
        "Ù…Ø¯Ù„ ØªØ±Ø¬Ù…Ù‡:",
        ["DeepSeek (Ø±Ø§ÛŒÚ¯Ø§Ù†)", "OpenAI (Ù†ÛŒØ§Ø² Ø¨Ù‡ API)"]
    )

# --- Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ---
uploaded_file = st.file_uploader(
    "ÙØ§ÛŒÙ„ Ø®ÙˆØ¯ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯", 
    type=["pdf", "txt", "srt"],
    help="PDF, ÙØ§ÛŒÙ„ Ù…ØªÙ†ÛŒ ÛŒØ§ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ SRT"
)

if uploaded_file:
    st.success(f"âœ… ÙØ§ÛŒÙ„ {uploaded_file.name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯!")
    
    # --- Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ ÙØ§ÛŒÙ„ ---
    if st.checkbox("Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØªÙˆØ§ÛŒ ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ"):
        text = extract_text_from_file(uploaded_file, file_type)
        st.text_area("Ù…Ø­ØªÙˆØ§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡", text, height=200)

    # --- ØªØ±Ø¬Ù…Ù‡ ---
    if st.button("ØªØ±Ø¬Ù…Ù‡ Ú©Ù†", type="primary"):
        with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ ØªØ±Ø¬Ù…Ù‡..."):
            try:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ†
                text = extract_text_from_file(uploaded_file, file_type)
                
                # ØªØ±Ø¬Ù…Ù‡
                if model_choice == "DeepSeek (Ø±Ø§ÛŒÚ¯Ø§Ù†)":
                    client = InferenceClient(
                        model="deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
                        token=os.getenv("HUGGINGFACE_TOKEN")
                    )
                    prompt = f"""
                    Ø´Ù…Ø§ ÛŒÚ© Ù…ØªØ±Ø¬Ù… Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù‡Ø³ØªÛŒØ¯. Ù…ØªÙ† Ø²ÛŒØ± Ø±Ø§ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù† ØªØ±Ø¬Ù…Ù‡ Ú©Ù†ÛŒØ¯:
                    {text}
                    """
                    translated = client.text_generation(prompt, max_new_tokens=3000)
                    time.sleep(2)  # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Rate Limit
                else:
                    openai.api_key = os.getenv("OPENAI_API_KEY")
                    response = openai.ChatCompletion.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": "Ù…ØªÙ† Ø±Ø§ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù† Ùˆ Ø¯Ù‚ÛŒÙ‚ ØªØ±Ø¬Ù…Ù‡ Ú©Ù†."},
                            {"role": "user", "content": text}
                        ]
                    )
                    translated = response.choices[0].message.content
                
                # Ù†Ù…Ø§ÛŒØ´ Ù†ØªÛŒØ¬Ù‡
                st.subheader("ØªØ±Ø¬Ù…Ù‡ Ù†Ù‡Ø§ÛŒÛŒ:")
                st.text_area("Ù…ØªÙ† ØªØ±Ø¬Ù…Ù‡â€ŒØ´Ø¯Ù‡", translated, height=300)
                
                # Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ PDF Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯
                pdf_path = create_pdf(translated)
                with open(pdf_path, "rb") as f:
                    st.download_button(
                        "Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØ±Ø¬Ù…Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª PDF",
                        f,
                        file_name=f"ØªØ±Ø¬Ù…Ù‡_{uploaded_file.name.split('.')[0]}.pdf",
                        mime="application/pdf"
                    )
                
            except Exception as e:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´: {str(e)}")
                st.error("Ù…Ù…Ú©Ù† Ø§Ø³Øª ÙØ§ÛŒÙ„ Ø¨Ø³ÛŒØ§Ø± Ø¨Ø²Ø±Ú¯ Ø¨Ø§Ø´Ø¯ ÛŒØ§ Ú©Ù„ÛŒØ¯ API Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø§Ø´Ø¯.")
